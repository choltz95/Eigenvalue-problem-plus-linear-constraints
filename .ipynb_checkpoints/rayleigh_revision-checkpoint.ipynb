{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orange3xchicken/.local/lib/python3.7/site-packages/jax/experimental/optimizers.py:30: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Callable, NamedTuple, Tuple, Union\n",
    "Step = int\n",
    "Schedule = Callable[[Step], float]\n",
    "\n",
    "from IPython import display\n",
    "from IPython.display import Image, clear_output\n",
    "from PIL import Image\n",
    "import glob, os, shutil\n",
    "import os.path\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import time\n",
    "\n",
    "import scipy.io as io\n",
    "from scipy import sparse as sp\n",
    "import scipy.sparse.csgraph as csgraph\n",
    "from scipy.sparse.csgraph import laplacian as csgraph_laplacian\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.linalg import null_space\n",
    "\n",
    "import jax\n",
    "from jax import jit, vmap, random, grad, value_and_grad, hessian\n",
    "from jax.experimental import optimizers, sparse\n",
    "from jax.experimental.optimizers import optimizer\n",
    "from jax import numpy as jnp\n",
    "\n",
    "from functools import partial\n",
    "import itertools\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import collections as mc\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from utils import *\n",
    "from optimizers import *\n",
    "from opt_widgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 351\n",
      "Number of edges: 975\n",
      "Average degree:   5.5556\n"
     ]
    }
   ],
   "source": [
    "# load the data from the SuiteSparse Matrix Collection format\n",
    "# https://www.cise.ufl.edu/research/sparse/matrices/\n",
    "graphs = ['qh882','dwt_1005','3elt','commanche_dual','bcsstk31']\n",
    "graphdir = './testcases/'\n",
    "graphpostfix = '3elt'\n",
    "assert graphpostfix in graphs\n",
    "grid_testcase = nx.grid_graph(dim=(50, 50))\n",
    "grid_testcase = nx.triangular_lattice_graph(25,25)\n",
    "#grid_testcase = nx.cycle_graph(100)\n",
    "grid_testcase_adjacency = nx.adjacency_matrix(grid_testcase).toarray().astype(np.int16)\n",
    "DEBUG=True\n",
    "if DEBUG:\n",
    "    graph, G, A, L, D, n = load_graph(graphdir+graphpostfix, A=grid_testcase_adjacency, plot_adjacency=False, verbose=True)\n",
    "else:\n",
    "    graph, G, A, L, D, n = load_graph(graphdir+graphpostfix, A=None, plot_adjacency=False, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del G\n",
    "del A\n",
    "del D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def newton(opt_tuple, A, Ax, Ay, P, L, C, E_0, maxiters=100, alpha=1e-2, beta=0.9):\n",
    "    \"\"\"Perform iterations of PND + backtracking line search.\"\"\"    \n",
    "    opt_state, opt_update, get_params = opt_tuple    \n",
    "    X_k = get_params(opt_state)\n",
    "    step_sizes = 1.0*jnp.power(0.9,jnp.linspace(0,100)) # geometric progression\n",
    "   \n",
    "    pAp, pAxp, pAyp = P@A@P.T, P@Ax@P.T, P@Ay@P.T \n",
    "    L = L_init(X_k, C, pAp, E_0)\n",
    "    \n",
    "    newton_trace = init_trace()\n",
    "    \n",
    "    def _line_search(s, Z):\n",
    "        opt_state_t = step(s, opt_state, -Z, opt_update)\n",
    "        X_k_t = get_params(opt_state_t)\n",
    "        f_xp = f(X_k_t, pAxp, pAyp, E_0)\n",
    "        return f_xp\n",
    "    \n",
    "    for k in tqdm(range(maxiters)):         \n",
    "        Z, Del = sqp(pAp, L, E_0, X_k)\n",
    "\n",
    "        f_x = f(X_k, pAxp, pAyp, E_0)\n",
    "        \n",
    "        _f_ks = vmap(_line_search,in_axes=(0,None))(step_sizes,Z)\n",
    "        _f_kamin = jnp.argmin(_f_ks.real)\n",
    "        f_xp = _f_ks[_f_kamin]\n",
    "        stp = step_sizes[_f_kamin]\n",
    "        \n",
    "        opt_state = step(stp, opt_state, -Z, opt_update)\n",
    "        X_k = get_params(opt_state)\n",
    "\n",
    "        L = L + stp*Del\n",
    "        foc = np.asarray(foc_sqp(X_k, L, C, pAp, E_0))\n",
    "\n",
    "        newton_trace = update_trace(newton_trace, [f_xp.item()], [stp.item()], \n",
    "                                    [(foc, foc)], \n",
    "                                    [(foc, foc)], [np.asarray(X_k)], [np.asarray(L)], [None])\n",
    "            \n",
    "    return newton_trace\n",
    "\n",
    "def ssm(opt_tuple, params, C, maxiters=10, alpha=0.0, beta=0.9):\n",
    "    \"\"\"1. compute newton direction z = sqp(X, Z, v, Ax + E0) & subspace S\n",
    "       2. approximate locally optimal X, L on S; X = min F(\\hat{X}, B, V.T@E0)\"\"\"\n",
    "    opt_state, opt_init, opt_update, get_params = opt_tuple\n",
    "    A, L, E_0, v_s = params['A'], params['L'], params['E_0'], params['v']\n",
    "    X_0 = get_params(opt_state)\n",
    "    PE_0 = PX(v_s,E_0)\n",
    "    I = sp_eye(A.shape[0])\n",
    "    \n",
    "    ssm_trace = init_trace()\n",
    "    \n",
    "    results = None\n",
    "    v = X_0    \n",
    "    \n",
    "    X_0_proj = project(X_0, C, E_0)\n",
    "    X_k = X_0_proj\n",
    "    for k in tqdm(range(maxiters)):     \n",
    "        Z, Del = scipy_sqp(X_k, A, None, L, PE_0, I)\n",
    "        Q,v = subspace(X_k, Z, v, A, PE_0, C)\n",
    "\n",
    "        QP = XP(Q.T, v_s)\n",
    "        QX_k = Q.T@X_k\n",
    "        QPE_0 = Q.T@PE_0\n",
    "        \n",
    "        # currently being recompiled. need to fix\n",
    "        opt_init, opt_update, get_params = psgd(partial(lambda x, y, z: project(z, y, x), \n",
    "                                                QPE_0, C))\n",
    "        \n",
    "        opt_state = opt_init(QX_k)  \n",
    "\n",
    "        newton_trace = newton((opt_state, opt_update, get_params), A,A,A, QP, L, C, QPE_0, \n",
    "                               maxiters=50, alpha=0.0, beta=0.9)         \n",
    "\n",
    "        argmin_loss = np.argmin(newton_trace['loss'])\n",
    "        X_k = newton_trace['solution_path'][argmin_loss]\n",
    "        L = newton_trace['lagrangian'][argmin_loss]\n",
    "        \n",
    "        X_k = Q@X_k\n",
    "        X_k_p = project(X_k, C, PE_0)\n",
    "        \n",
    "        ssm_trace = update_trace(ssm_trace, newton_trace['loss'], newton_trace['step_size'], \n",
    "                                 newton_trace['opt_conditions'], \n",
    "                                 newton_trace['constraints'], newton_trace['solution_path'], \n",
    "                                 newton_trace['lagrangian'], [np.asarray(Q)]*len(newton_trace['loss']))\n",
    "    return X_k_p, ssm_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_problem(rng, A, X, v, mask):\n",
    "    \"\"\"takes problem parameters returns a params tuple = instance of problem \"\"\"\n",
    "    def _compute_problem_vars(A, X, mask):\n",
    "        \"\"\"Computes Laplacian decomposition, linear terms in the objective\"\"\"\n",
    "        X_1 = X[~mask]\n",
    "        A_12 = A[~mask, :][:, mask]\n",
    "\n",
    "        A = sparse.BCOO.from_scipy_sparse(A[mask, :][:,mask])\n",
    "        \n",
    "        print('rqi...')\n",
    "        eigenvectors, eigenvalues = rqi(A, eps=1e-5, s=0.0)\n",
    "        print('eigenvalues: ', np.round(np.array(eigenvalues.real), decimals=5))\n",
    "\n",
    "        X0 = complete_matrix(eigenvectors[:,:2], X_1, mask)\n",
    "        E_0 = (X_1.T@A_12).T\n",
    "\n",
    "        return A, X0, E_0\n",
    "    \n",
    "    A, X0, E_0 = _compute_problem_vars(A, X, mask)\n",
    "    params = init_params(A, A, A, X0, mask, E_0, v)\n",
    "    return params\n",
    "\n",
    "def solve_problem(rng, opt_params, params, C):\n",
    "    opt_init, opt_update, get_params = opt_params\n",
    "    X_0 = params['X'][params['mask']]\n",
    "    opt_state = opt_init(X_0)\n",
    "    opt_tuple = (opt_state, opt_init, opt_update, get_params)\n",
    "    print('ssm...')\n",
    "    X_k_p, ssm_trace = ssm(opt_tuple, params, C, maxiters=10, alpha=0.0, beta=0.9)\n",
    "    X = complete_matrix(X_k_p, params['X'][~params['mask']],params['mask'])\n",
    "    return X, ssm_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed = 0 # random seed\n",
    "eps = 1e-8 # global epsilon variable\n",
    "rng = random.PRNGKey(seed)\n",
    "key, subkey = jax.random.split(rng)\n",
    "\n",
    "c1 = c2 = n*10**2*1/12\n",
    "c3=0\n",
    "C = jnp.block([[c1, c3],[c3, c2]])\n",
    "\n",
    "X_k_r = (random.normal(subkey, (n,2))*np.sqrt(10))\n",
    "\n",
    "if DEBUG:\n",
    "    fixed_indices = np.array([0])\n",
    "else:\n",
    "    fixed_indices = np.array([0,1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "X_k_r = X_k_r.at[0,0].set(0)\n",
    "X_k_r = X_k_r.at[0,1].set(-1)\n",
    "#X_k[fixed_indices] = X_k_r[fixed_indices]\n",
    "X_k = np.array(X_k_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rqi...\n",
      "eigenvalue 1: 0.033\n",
      "eigenvalue 2: 0.084\n",
      "eigenvalues:  [0.03268 0.08367]\n",
      "ssm...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7456918b37d24f5aba5c8bb25bdcd211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orange3xchicken/.local/lib/python3.7/site-packages/jax/_src/numpy/lax_numpy.py:6690: UserWarning: Explicitly requested dtype <class 'numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lax._check_user_dtype_supported(dtype, \"astype\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d478fc39485f418d9a0db3a986c24366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orange3xchicken/.local/lib/python3.7/site-packages/jax/_src/numpy/lax_numpy.py:6690: UserWarning: Explicitly requested dtype <class 'numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lax._check_user_dtype_supported(dtype, \"astype\")\n",
      "/home/orange3xchicken/.local/lib/python3.7/site-packages/jax/_src/lax/lax.py:473: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return _convert_element_type(operand, new_dtype, weak_type=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02beb65fbc0b4401a79cfd4c4ce6cdf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46ca974c3da4e6da5c6c65cf7e5d646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = jnp.ones((X_k.shape[0],),dtype=bool)\n",
    "mask = mask.at[fixed_indices].set(False)\n",
    "v = np.ones((mask.sum(),1))/np.sqrt(mask.sum())\n",
    "params = create_problem(rng, L, X_k, v, mask)\n",
    "opt_tuple = psgd(partial(lambda x, y, z: project(z, y, x), \n",
    "                         np.zeros((8,2)), C))\n",
    "X, result = solve_problem(rng, opt_tuple, params, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resgraph = utils.plot_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "voxel_id, voxel_bound = voxel_cluster(X_k, np.array([5, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_graph(X, graph, title='loss: {} h: {} g: {} foc: {}', fixed_indices=fixed_indices, c=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
