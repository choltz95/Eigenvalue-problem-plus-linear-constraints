{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import Any, Callable, NamedTuple, Tuple, Union\n",
    "Step = int\n",
    "Schedule = Callable[[Step], float]\n",
    "\n",
    "from IPython import display\n",
    "from IPython.display import Image, clear_output\n",
    "from PIL import Image\n",
    "import glob, os, shutil\n",
    "import os.path\n",
    "\n",
    "import time\n",
    "\n",
    "import scipy.io as io\n",
    "import scipy.sparse.csgraph as csgraph\n",
    "from scipy.sparse.csgraph import laplacian as csgraph_laplacian\n",
    "import scipy as sp\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.linalg import null_space\n",
    "\n",
    "import jax\n",
    "from jax import jit, vmap, random, grad, value_and_grad, hessian\n",
    "from jax.experimental import optimizers, sparse\n",
    "from jax.experimental.optimizers import optimizer\n",
    "from jax import numpy as jnp\n",
    "\n",
    "from functools import partial\n",
    "import itertools\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import collections as mc\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from utils import *\n",
    "from optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 2500\n",
      "Number of edges: 4900\n",
      "Average degree:   3.9200\n"
     ]
    }
   ],
   "source": [
    "# load the data from the SuiteSparse Matrix Collection format\n",
    "# https://www.cise.ufl.edu/research/sparse/matrices/\n",
    "graphs = ['qh882','dwt_1005','3elt','commanche_dual','bcsstk31']\n",
    "graphdir = './testcases/'\n",
    "graphpostfix = '3elt'\n",
    "assert graphpostfix in graphs\n",
    "grid_testcase = nx.grid_graph(dim=(50, 50))\n",
    "#grid_testcase = nx.triangular_lattice_graph(25,25)\n",
    "#grid_testcase = nx.cycle_graph(100)\n",
    "grid_testcase_adjacency = nx.adjacency_matrix(grid_testcase).toarray().astype(np.int16)\n",
    "DEBUG=True\n",
    "if DEBUG:\n",
    "    graph, G, A, L, D, n = load_graph(graphdir+graphpostfix, A=grid_testcase_adjacency, plot_adjacency=False, verbose=True)\n",
    "else:\n",
    "    graph, G, A, L, D, n = load_graph(graphdir+graphpostfix, A=None, plot_adjacency=False, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del G\n",
    "del A\n",
    "del D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def project(X1, C, E_0, c=jnp.array([0,0])):\n",
    "    C1 = X1.T@X1\n",
    "    C1sqrt = utils._sqrtm(C1)\n",
    "    Csqrt = utils._sqrtm(C)\n",
    "    U,s,V = jnp.linalg.svd(Csqrt@C1sqrt)\n",
    "    X = X1@jnp.linalg.inv(C1sqrt)@U@V.T@Csqrt\n",
    "\n",
    "    U_E, _, V_E = jnp.linalg.svd(X.T@E_0)\n",
    "    X = X@(-U_E@V_E.T)\n",
    "    return X.real\n",
    "\n",
    "@partial(jit, static_argnums=(3,))\n",
    "def step(i, opt_state, Z, opt_update):\n",
    "    \"\"\"Perform a single descent + projection step with arbitrary descent direction.\"\"\"\n",
    "    return opt_update(i, Z, opt_state)\n",
    "\n",
    "def _D_Z(X, A, P, d, e):\n",
    "    I = jnp.eye(A.shape[0])\n",
    "    Ad = A + d*I\n",
    "    \n",
    "    Del = jnp.linalg.solve(X.T@jnp.linalg.solve(Ad, X), X.T)@jnp.linalg.solve(Ad, e)\n",
    "    Z = jnp.linalg.solve(Ad, -X@Del + e)\n",
    "    \n",
    "    return Del, Z\n",
    "\n",
    "@jit\n",
    "def _sqp(A, P, L, E_0, X):\n",
    "    \"\"\"Perform an iteration of SQP.\"\"\" \n",
    "    w = jnp.linalg.eigvals(L)\n",
    "    idx = w.argsort() \n",
    "    w = w[idx]\n",
    "    E = -E_0 - (A@X + X@L)\n",
    "\n",
    "    Del_0, Z_0 = _D_Z(X, A, P, w[0], E[:,0])\n",
    "    Del_1, Z_1 = _D_Z(X, A, P, w[1], E[:,1])\n",
    "    \n",
    "    Z = jnp.stack([Z_0, Z_1], axis=1)\n",
    "    Del = jnp.stack([Del_0, Del_1], axis=1)\n",
    "    \n",
    "    return Z, Del  \n",
    "@jit\n",
    "def D_Z(X, A, P, d, e, I):\n",
    "    Ad = A + d*I\n",
    "\n",
    "    #ADinvP = jnp.linalg.solve(Ad, P.T)\n",
    "    sp_solve = lambda A, b:jnp.array(sp.linalg.solve(A,b))\n",
    "    #sp_solve = lambda _, x: jax.scipy.sparse.linalg.bicgstab(lambda b:Ad@b, x, M=lambda b:M@b, maxiter=100)[0]\n",
    "    #sp_solve = lambda _, x: jax.scipy.sparse.linalg.gmres(lambda b:Ad@b , x, maxiter=100, solve_method='incremental',M=jnp.linalg.inv(Ad))[0]\n",
    "    ADinvP = sp_solve(Ad, P.T)\n",
    "    \n",
    "    #Del = jnp.linalg.solve(X.T@(jnp.linalg.solve(Ad,X)),X.T)@jnp.linalg.solve(Ad,e)\n",
    "    Del = jnp.linalg.solve(X.T@(sp_solve(Ad,X)),X.T)@sp_solve(Ad,e)\n",
    "    \n",
    "    Z = P@(ADinvP@(P@(-X@Del + e)))\n",
    "\n",
    "    return Del, Z\n",
    "\n",
    "@jit\n",
    "def sqp(X, A, P, L, E_0, I):\n",
    "    \"\"\"Perform an iteration of SQP.\"\"\" \n",
    "    w = jnp.linalg.eigvals(L)\n",
    "    idx = w.argsort()  \n",
    "    w = w[idx].real\n",
    "    E = -E_0 - (A@X + X@L)\n",
    "    Del_0, Z_0 = D_Z(X, A, M, P, w[0], E[:,0], I)\n",
    "    Del_1, Z_1 = D_Z(X, A, M, P, w[1], E[:,1], I)\n",
    "    \n",
    "    Z = jnp.stack([Z_0, Z_1], axis=1)\n",
    "    Del = jnp.stack([Del_0, Del_1], axis=1)\n",
    "    \n",
    "    return Z, Del  \n",
    "\n",
    "def scipy_sqp(X, A, P, L, E_0, I):\n",
    "    \"\"\"Perform an iteration of SQP.\"\"\" \n",
    "    w = jnp.linalg.eigvals(L)\n",
    "    idx = w.argsort()  \n",
    "    w = w[idx].real\n",
    "    E = -E_0 - (A@X + X@L)\n",
    "    Del_0, Z_0 = scipy_D_Z(X, A, P, w[0], E[:,0], I)\n",
    "    Del_1, Z_1 = scipy_D_Z(X, A, P, w[1], E[:,1], I)\n",
    "    \n",
    "    Z = jnp.stack([Z_0, Z_1], axis=1)\n",
    "    Del = jnp.stack([Del_0, Del_1], axis=1)\n",
    "    \n",
    "    return Z, Del  \n",
    "\n",
    "def scipy_D_Z(X, A, P, d, e, I):\n",
    "    Ad = A + d*I\n",
    "\n",
    "    #ADinvP = jnp.linalg.solve(Ad, P.T)\n",
    "    #sp_solve = lambda _, x: bicgstab(lambda b:Ad@b , x, maxiter=100)[0]\n",
    "    Ad = sp.sparse.coo_matrix((A.data, (A.indices[:,0], A.indices[:,1]))).tocsr()\n",
    "    sp_solve = lambda A, b:jnp.array(sp.sparse.linalg.spsolve(A,b))\n",
    "    #sp_solve = lambda A, b:jnp.array(sp.sparse.linalg.bicgstab(A,b))\n",
    "    ADinvP = sp_solve(Ad, P.T)\n",
    "    \n",
    "    Del = jnp.linalg.solve(X.T@(sp_solve(Ad,X)),X.T)@sp_solve(Ad,e)\n",
    "    \n",
    "    Z = P@(ADinvP@(P@(-X@Del + e)))\n",
    "\n",
    "    return Del, Z\n",
    "\n",
    "\n",
    "def newton(opt_params, A, P, L, C, X_k, b_x, b_y, convergence_criterion, \n",
    "           maxiters=20, alpha=1e-2, beta=0.9, initL=True):\n",
    "    \"\"\"Perform iterations of PND + backtracking line search.\"\"\"    \n",
    "    opt_state, opt_update, get_params = opt_params\n",
    "    X_k = get_params(opt_state)\n",
    "    E_0 = np.stack([b_x, b_y], axis=1)\n",
    "   \n",
    "    pAp = P@A@P.T\n",
    "\n",
    "    if initL:\n",
    "        L = L_init(X_k, C, pAp, E_0)\n",
    "    \n",
    "    report = {'x':None, 'lossh':[f(X_k, pAp, pAp, b_x, b_y).item()], 'sln_path':[np.asarray(X_k)], \n",
    "            'foc':[foc_sqp(X_k, L, C, pAp, E_0).item()], 'step_sizes':[1], 'L':[L]}\n",
    "    \n",
    "    cc = 0\n",
    "    \n",
    "    for k in tqdm(range(maxiters)):         \n",
    "        #Z, Del = sqp(A, P, pAp, L, E_0, X_k)\n",
    "        Z, Del = _sqp(pAp, P, L, E_0, X_k)\n",
    "        \n",
    "        # backtracking line search\n",
    "        f_xp = 1e8\n",
    "        stp = 1\n",
    "        f_x, gr = value_and_grad(f)(X_k, pAp, pAp, b_x, b_y)\n",
    "        len_p = jnp.linalg.norm(Z)\n",
    "        X_k_t = X_k\n",
    "        \n",
    "        opt_state_t = opt_state\n",
    "        \n",
    "        while f_xp >= f_x:\n",
    "            stp *= beta\n",
    "            opt_state_t = step(stp, opt_state, -Z, opt_update)\n",
    "            X_k_t = get_params(opt_state_t)\n",
    "            f_xp = f(X_k_t, pAp, pAp, b_x, b_y)\n",
    "        \n",
    "            if stp * len_p < 1e-8:\n",
    "                break  \n",
    "                \n",
    "        L = L + stp*Del\n",
    "        foc = foc_sqp(X_k, L, C, pAp, E_0)\n",
    "        \n",
    "        opt_state = opt_state_t\n",
    "        X_k = get_params(opt_state_t)\n",
    "        \n",
    "        if f_xp > report['lossh'][-1]:\n",
    "            break\n",
    "        \n",
    "        report['sln_path'].append(np.asarray(X_k))\n",
    "        report['step_sizes'].append(stp)\n",
    "        report['foc'].append(foc.item())\n",
    "        report['lossh'].append(f_xp.item())\n",
    "        report['L'].append(np.asarray(L))\n",
    "        \n",
    "        if len(report['lossh']) > 2 and np.abs(foc.item()) <= convergence_criterion:\n",
    "            cc += 1\n",
    "            if cc > 10:\n",
    "                print('converged')\n",
    "                break\n",
    "        if cc > 0:\n",
    "            cc -= 1\n",
    "            \n",
    "    return report\n",
    "\n",
    "@jit\n",
    "def subspace(X_k_q, X_k, Z, v, A, E_0, E_00, P, C):\n",
    "    AXE = P@(A@X_k+E_0)\n",
    "    #Q, _ = jnp.linalg.qr(jnp.concatenate([X_k_q, Z, v, AXE],axis=-1), mode='reduced')\n",
    "    Q, _ = jnp.linalg.qr(jnp.concatenate([X_k_q, v, AXE],axis=-1), mode='reduced')\n",
    "    PQ = P.T@Q\n",
    "    B=PQ.T@(A@PQ)\n",
    "    \n",
    "    #X_k = jnp.linalg.pinv(PQ)@X_k\n",
    "    X_k = PQ.T@X_k\n",
    "    E_0 = PQ.T@E_00\n",
    "    X_k = project(X_k, C, E_0)\n",
    "    \n",
    "    w_v, v_v = jnp.linalg.eig(B)\n",
    "    idx = w_v.argsort()\n",
    "    v_v = v_v[idx]\n",
    "    v = Q@v_v[:,1:3]\n",
    "    PQE_0 = PQ@E_0\n",
    "    \n",
    "    return Q, PQ, B, X_k, E_0, PQE_0, v\n",
    "    \n",
    "def ssm(opt_params, A, P, L, C, X_k, b_x, b_y, convergence_criterion, \n",
    "        maxiters=10, alpha=1e-2, beta=0.9):\n",
    "    \"\"\"\n",
    "    1. compute newton direction z = sqp(X, Z, v, Ax + E0) & subspace S\n",
    "    2. approximate locally optimal X, L on S; X = min F(\\hat{X}, B, V.T@E0)\n",
    "    \"\"\"\n",
    "    opt_state, opt_init, opt_update, get_params = opt_params\n",
    "    X_k = get_params(opt_state)\n",
    "    \n",
    "    E_00 = jnp.stack([b_x, b_y], axis=1)\n",
    "       \n",
    "    cc = 0\n",
    "    L = jnp.eye(2)\n",
    "    results = None\n",
    "    E_0 = E_00\n",
    "    X_k_q = P@X_k\n",
    "    #v = jnp.zeros_like(X_k_q)\n",
    "    \n",
    "    w_v, v_v = jnp.linalg.eig(P@A@P.T)\n",
    "    idx = w_v.argsort()\n",
    "    v_v = v_v[idx]\n",
    "    v = v_v[:,:5]\n",
    "    \n",
    "    I = jnp.eye(A.shape[0])\n",
    "    I = sparse.BCOO.fromdense(I)\n",
    "    M = None \n",
    "    for k in tqdm(range(maxiters)):     \n",
    "        'Subspace computation'\n",
    "        #Z, Del = sqp(X_k, A, Ad, M, P, L, E_0, I)\n",
    "        Z, Del = scipy_sqp(X_k, A, P, L, E_0, I)\n",
    "        #Z = None\n",
    "\n",
    "        'initialize wrt subspace'\n",
    "        #if k > 1:\n",
    "        #    print('before sub',f(X_k, A, A, E_00[:,0], E_00[:,1]))\n",
    "        qq, Q, B, X_k, E_0, QE_0, _ = subspace(X_k_q, X_k, Z, v, A, E_0, E_00, P, C)\n",
    "        #print('after sub',f(Q@X_k, A, A, E_00[:,0], E_00[:,1]))\n",
    "        \n",
    "        opt_init, opt_update, get_params = psgd(partial(lambda x, y, z: z, \n",
    "                                                        E_0, C))    \n",
    "        \n",
    "        opt_state = opt_init(X_k)       \n",
    "        result = newton((opt_state, opt_update, get_params), A, Q.T, L, C, X_k, E_0[:,0], E_0[:,1], \n",
    "                        convergence_criterion=convergence_criterion, maxiters=20, alpha=0.0, beta=0.9, initL=True) \n",
    "        \n",
    "        X_k = result['sln_path'][-1]\n",
    "        L = result['L'][-1]\n",
    "        #print('inner',f(X_k, Q.T@A@Q, Q.T@A@Q, E_00[:,0]@Q, E_00[:,1]@Q))\n",
    "        X_k_q = qq@X_k # QX\n",
    "        X_k = Q@X_k    # PQX\n",
    "        E_0 = QE_0     # PQE\n",
    "        X_k = project(X_k, C, E_0)\n",
    "        #print('outer',f(X_k, A, A, E_0[:,0], E_0[:,1]))\n",
    "        if results == None:\n",
    "            results = result\n",
    "            results['sln_path'] = [X_k]\n",
    "            results['lossh'] = [result['lossh'][-1]]            \n",
    "        \n",
    "        results['lossh'].extend(result['lossh'])\n",
    "        results['sln_path'].extend([X_k]*len(result['lossh']))\n",
    "        results['foc'].extend(result['foc'])\n",
    "        results['step_sizes'].extend(result['step_sizes'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def transform_A(A, X_k, boolean_idx):\n",
    "    boolean_fixed_idx, boolean_nonfixed_idx = boolean_idx\n",
    "    X_1x = X_k[boolean_fixed_idx,0]\n",
    "    X_1y = X_k[boolean_fixed_idx,1]\n",
    "    X_2  = X_k[boolean_nonfixed_idx]\n",
    "    A_12 = A[boolean_fixed_idx, :]\n",
    "    A_12 = A_12[:, boolean_nonfixed_idx] \n",
    "    b_x = X_1x@A_12\n",
    "    b_y = X_1y@A_12\n",
    "    A = A[boolean_nonfixed_idx, :]\n",
    "    A = A[:,boolean_nonfixed_idx]\n",
    "    \n",
    "    return A, X_1x, X_1y, X_2, b_x, b_y\n",
    "\n",
    "def map_vars(A, X_k, fixed_idx, centercons, decomp=True):\n",
    "    \"\"\"Preprocess variables \"\"\" \n",
    "    N = A.shape[0] \n",
    "    k = fixed_indices.shape[0]\n",
    "    fixed_idx = jnp.zeros((k,N))\n",
    "    for i in range(k):\n",
    "        fixed_idx=jax.ops.index_add(fixed_idx,jnp.index_exp[i, fixed_indices[i]],1)\n",
    "\n",
    "    boolean_fixed_idx = fixed_idx.sum(0).astype(bool)\n",
    "    boolean_nonfixed_idx = (1-fixed_idx.sum(0)).astype(bool)\n",
    "    \n",
    "    A, X_1x, X_1y, X_2, b_x, b_y = transform_A(A, X_k, (boolean_fixed_idx, boolean_nonfixed_idx))\n",
    "    X_k = X_2\n",
    "    \n",
    "    P = jnp.eye(A.shape[0])\n",
    "\n",
    "    constraints = np.expand_dims(np.ones(X_2.shape[0]),0)\n",
    "    #P = qr_null(constraints).T\n",
    "    Q, rnk = qr_null(constraints)\n",
    "    Q = Q[:, rnk:].conj().T\n",
    "    P = Q * np.sign(P[0,0])\n",
    "\n",
    "    #pinvcons = jnp.linalg.pinv(constraints)\n",
    "    #n0_x = pinvcons@(np.expand_dims(centercons[0],0))\n",
    "    n0_x = jnp.zeros_like(b_x)\n",
    "    if centercons[1] == centercons[0]:\n",
    "        n0_y = n0_x\n",
    "    else:\n",
    "        n0_y = pinvcons@(np.expand_dims(centercons[1],0))\n",
    "\n",
    "    return X_k, A, P, b_x, b_y, n0_x, n0_y, fixed_idx\n",
    "    \n",
    "\n",
    "def cluster(rng, opt_params, X_k, fixed_x, A, mapped_vars, fixed_indices=None, maxiters=1000, convergence_criterion=1e-3,\n",
    "            c1=1, c2=1, c3=0, centroid=jnp.array([0,0]), centercons=None, v=None, D=None, eps=1e-8, method='pgd'):\n",
    "    \"\"\"Given an adjacency matrix A and initialization X_k, optimize X.\"\"\"\n",
    "    method = method.lower()\n",
    "    opt_init, opt_update, get_params = opt_params    \n",
    "        \n",
    "    k = fixed_x.shape[0]\n",
    "    if fixed_indices is None:\n",
    "        fixed_coordsx = fixed_x[:,0]\n",
    "        fixed_coordsy = fixed_x[:,1]\n",
    "    else:\n",
    "        fixed_coordsx = X_k[fixed_indices,0]\n",
    "        fixed_coordsy = X_k[fixed_indices,1]\n",
    "    \n",
    "    N = A.shape[0]\n",
    "\n",
    "    if v is None:\n",
    "        v = jnp.ones(N)\n",
    "    if D is None:\n",
    "        D = jnp.diag(v)\n",
    "    if centercons is None:\n",
    "        centercons = jnp.zeros(2)\n",
    "    A, P, b_x, b_y, n0_x, n0_y, fixed_idx = mapped_vars\n",
    "\n",
    "    C = jnp.block([[c1, c3],[c3, c2]])\n",
    "    assert jnp.linalg.det(C) > 1e-5\n",
    "    \n",
    "    E_0 = jnp.stack([b_x, b_y], axis=1)\n",
    "    n0 = jnp.stack([n0_x,n0_y],axis=0)\n",
    "    #X_k_n = jnp.array(np.linalg.pinv(P.T)@(X_k-n0.T))\n",
    "    X_k_n = X_k\n",
    "    X_k_n = project(X_k_n, C, E_0, centercons)\n",
    "    L = jnp.eye(2)\n",
    "\n",
    "    opt_state = opt_init(X_k_n) #pap\n",
    "    result = ssm((opt_state, opt_init, opt_update, get_params), A, P, L, C, X_k_n, b_x, b_y, \n",
    "                    convergence_criterion=convergence_criterion, maxiters=maxiters, alpha=0.0, beta=0.9) \n",
    "\n",
    "    X_k = result['sln_path'][np.argmin(result['lossh'])]\n",
    "\n",
    "    X_k_n = np.zeros((N,2))\n",
    "    if fixed_indices is None:\n",
    "        X_k_n[:,0] = np.concatenate([fixed_coordsx, np.array(X_k[:,0]) + n0_x.T])\n",
    "        X_k_n[:,1] = np.concatenate([fixed_coordsy, np.array(X_k[:,1]) + n0_y.T])\n",
    "    else:\n",
    "        X_k_n[:,0] = np.array(P.T@X_k[:,0]) + n0_x.T\n",
    "        X_k_n[:,1] = np.array(P.T@X_k[:,1]) + n0_y.T\n",
    "        \n",
    "    result['x'] = X_k_n\n",
    "    \n",
    "    mask = (1-fixed_idx.sum(0)).astype(np.bool)\n",
    "    result['mask'] = mask\n",
    "    result['centroid'] = centercons\n",
    "    if fixed_idx.sum() == 0:\n",
    "        result['g'] = np.array(g(X_k_n, v, centercons))\n",
    "        result['h'] = np.array(h(X_k_n, np.diag(v), c1, c2, c3, centroid))      \n",
    "    else:\n",
    "        # need to insert at mask, not cat/stack\n",
    "        result['g'] = np.array(g(X_k_n[mask], v[mask], centercons))\n",
    "        result['h'] = np.array(h(X_k_n[mask], np.diag(v[mask]), c1, c2, c3, centroid))\n",
    "    result['P'] = (P)\n",
    "    result['e'] = np.vstack([b_x,b_y])\n",
    "    result['n'] = (n0_x, n0_y)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### USER PARAMETERS #####\n",
    "method = \"ssm\" # pnd, ssm, or pgd\n",
    "\n",
    "\n",
    "seed = 0 # random seed\n",
    "eps = 1e-8 # global epsilon variable\n",
    "rng = random.PRNGKey(seed)\n",
    "key, subkey = jax.random.split(rng)\n",
    "\n",
    "v = np.ones(n)\n",
    "c1=v.sum()*10**2*1/12\n",
    "c2=v.sum()*10**2*1/12\n",
    "c3=0\n",
    "C = jnp.block([[c1, c3],[c3, c2]])\n",
    "\n",
    "X_k_r = (random.normal(subkey, (n,2))*np.sqrt(10))\n",
    "\n",
    "if os.path.isfile(graphdir+graphpostfix+'_evals.npy') and \\\n",
    "   os.path.isfile(graphdir+graphpostfix+'_evecs.npy'):\n",
    "    w = np.load(graphdir+graphpostfix+'_evals.npy')\n",
    "    v = np.load(graphdir+graphpostfix+'_evecs.npy')    \n",
    "else:\n",
    "    w,v = sp.sparse.linalg.eigsh(L, k=min(n,5), which='SM')\n",
    "    np.save(graphdir+graphpostfix+'_evals.npy',w)\n",
    "    np.save(graphdir+graphpostfix+'_evecs.npy',v)\n",
    "if DEBUG:\n",
    "    w,v = sp.sparse.linalg.eigsh(L, k=min(n,5), which='SM')\n",
    "X_k = v[:,1:3].real\n",
    "\n",
    "if DEBUG:\n",
    "    fixed_indices = np.array([0])\n",
    "else:\n",
    "    fixed_indices = np.array([0,1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "\n",
    "X_k[fixed_indices] = X_k_r[fixed_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del w\n",
    "del v\n",
    "#del X_k_r\n",
    "v = jnp.ones(n)\n",
    "\n",
    "X_k, A, P, b_x, b_y, n0_x, n0_y, fixed_idx = map_vars(L, X_k, fixed_indices, v.sum()*jnp.array([0,0]))\n",
    "A = sparse.BCOO.from_scipy_sparse(A)\n",
    "mapped_vars = (A, P, b_x, b_y, n0_x, n0_y, fixed_idx)\n",
    "\n",
    "if method == \"pgd\":\n",
    "    pgd_lr = 5e-2\n",
    "    opt_init, opt_update, get_params = padam(pgd_lr,partial(lambda x, y, z: project(z, y, x), \n",
    "                                                    np.stack([b_x,b_y],axis=1), C), b1=0.9, b2=0.999, eps=1e-08)\n",
    "elif method == \"pnd\":\n",
    "    opt_init, opt_update, get_params = psgd(partial(lambda x, y, z: project(z, y, x), \n",
    "                                                    np.stack([b_x,b_y],axis=1), C))\n",
    "elif method == 'ssm':\n",
    "    opt_init, opt_update, get_params = psgd(partial(lambda x, y, z: project(z, y, x), \n",
    "                                                    np.zeros((8,2)), C))       \n",
    "else:\n",
    "    print('method not supported')\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0932c92723747adb2032f29f4287e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909637bb8c654f47b70dd26f18ad8920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%prun\n",
    "\n",
    "result = cluster(rng, (opt_init, opt_update, get_params), \n",
    "                 X_k, X_k_r[fixed_indices], L, mapped_vars, fixed_indices=None, c1=c1, c2=c2, c3=c3, centercons=v.sum()*jnp.array([0,0]), \n",
    "                 v=None, D=None, eps=1e-8, maxiters=10, convergence_criterion=1e-3, method=method)\n",
    "results = [result]\n",
    "X_k_n=result['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(np.linalg.eig(result['L'][-1].real),\n",
    "#      np.sort(np.linalg.eig(P@A@P.T)[0])[:5],\n",
    "#      np.sort(np.linalg.eig(A)[0])[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f(X_k_n, L, L, np.zeros(X_k_n.shape[0]), np.zeros(X_k_n.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resgraph = utils.plot_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "voxel_id, voxel_bound = voxel_cluster(X_k, np.array([5, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#utils.plot_graph(X_k, graph, title='loss: {} h: {} g: {} foc: {}'.format(str(np.round(np.min(result['lossh']),2)), \n",
    "#                                                                            np.round(result['g'],2), np.round(result['g'],2), \n",
    "#                                                                           str(np.round(result['foc'][np.argmin(result['lossh'])],2))), fixed_indices=fixed_indices, c=voxel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "utils.plot_graph(X_k_n, graph, title='loss: {} h: {} g: {} foc: {}'.format(str(np.round(np.min(result['lossh']),2)), \n",
    "                                                                            np.round(result['h'],2), np.round(result['g'],2), \n",
    "                                                                           str(np.round(result['foc'][np.argmin(result['lossh'])],2))), fixed_indices=fixed_indices, c=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#utils.plot_animation(results, graph, fixed_coordinates=X_k_r[fixed_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
