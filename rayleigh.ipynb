{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, NamedTuple, Tuple, Union\n",
    "Step = int\n",
    "Schedule = Callable[[Step], float]\n",
    "\n",
    "from IPython import display\n",
    "from IPython.display import Image, clear_output\n",
    "from PIL import Image\n",
    "import glob, os, shutil\n",
    "import os.path\n",
    "\n",
    "import time\n",
    "\n",
    "import scipy.io as io\n",
    "import scipy.sparse.csgraph as csgraph\n",
    "from scipy.sparse.csgraph import laplacian as csgraph_laplacian\n",
    "import scipy as sp\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.linalg import null_space\n",
    "\n",
    "import jax\n",
    "from jax import jit, vmap, random, grad, value_and_grad, hessian\n",
    "from jax.experimental import optimizers\n",
    "from jax.experimental.optimizers import optimizer\n",
    "from jax import numpy as jnp\n",
    "\n",
    "from functools import partial\n",
    "import itertools\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import collections as mc\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from utils import *\n",
    "from optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 4720\n",
      "Number of edges: 13722\n",
      "Average degree:   5.8144\n"
     ]
    }
   ],
   "source": [
    "# load the data from the SuiteSparse Matrix Collection format\n",
    "# https://www.cise.ufl.edu/research/sparse/matrices/\n",
    "graphs = ['qh882','dwt_1005','3elt','commanche_dual','bcsstk31']\n",
    "graphdir = './testcases/'\n",
    "graphpostfix = '3elt'\n",
    "assert graphpostfix in graphs\n",
    "grid_testcase = nx.grid_graph(dim=(20, 20))\n",
    "grid_testcase_adjacency = nx.adjacency_matrix(grid_testcase).toarray().astype(np.int16)\n",
    "DEBUG=True\n",
    "if DEBUG:\n",
    "    graph, G, A, L, D, n = load_graph(graphdir+graphpostfix, A=grid_testcase_adjacency, plot_adjacency=False, verbose=True)\n",
    "else:\n",
    "    graph, G, A, L, D, n = load_graph(graphdir+graphpostfix, A=None, plot_adjacency=False, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del G\n",
    "del A\n",
    "del D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def project(X1, C, E_0, c=jnp.array([0,0])):\n",
    "    C1 = X1.T@X1\n",
    "    C1sqrt = utils._sqrtm(C1)\n",
    "    Csqrt = utils._sqrtm(C)\n",
    "    U,s,V = jnp.linalg.svd(Csqrt@C1sqrt)\n",
    "    X = X1@jnp.linalg.inv(C1sqrt)@U@V.T@Csqrt\n",
    "\n",
    "    negdef = jnp.all(jnp.linalg.eigvals(X.T@E_0) <= 0)\n",
    "    U_E, _, V_E = jnp.linalg.svd(X.T@E_0)\n",
    "    X = jax.lax.cond(negdef,\n",
    "                     lambda _ : X@(-U_E@V_E.T),\n",
    "                     lambda _ : X,\n",
    "                     operand=None\n",
    "                    )\n",
    "    return X.real\n",
    "\n",
    "@jit\n",
    "def _step_noautograd(stp, X_k, A_x, A_y, b_x, b_y):\n",
    "    \"\"\"Perform a single gradient (using autograd) + projection step with adaptive momentum.\"\"\"\n",
    "    E_0 = stp*jnp.vstack([b_x,b_y]).T\n",
    "    X_k_x = X_k[:,0] - stp*A_x@X_k[:,0]\n",
    "    X_k_y = X_k[:,1] - stp*A_y@X_k[:,1]\n",
    "    X_k_t = jnp.vstack([X_k_x,X_k_y]).T - E_0\n",
    "    X_k_t = project(X_k_t, C, E_0)\n",
    "    return X_k_t\n",
    "\n",
    "def pgd(X_k, A_x, A_y, b_x, b_y, C, convergence_criterion, \n",
    "           maxiters=1000, alpha=1e-2, beta=0.9):\n",
    "    \"\"\"Perform iterations of PGD, without autograd.\"\"\"\n",
    "    E_0 = jnp.stack([b_x, b_y], axis=1)\n",
    "    L = jnp.linalg.inv(C)@X_k.T@(A_x@X_k+E_0)\n",
    "    \n",
    "    report = {'x':None, 'lossh':[f(X_k, A_x, A_y, b_x, b_y).item()], 'sln_path':[np.asarray(X_k)], \n",
    "            'foc':[foc_pgd(X_k, L, C, A_x, b_x, b_y).item()], 'step_sizes':[1], 'L':[L]}\n",
    "    \n",
    "    for k in tqdm(range(maxiters)):\n",
    "        # backtracking line search\n",
    "        f_xp = 1e8\n",
    "        stp = 1\n",
    "\n",
    "        f_x, g = value_and_grad(f)(X_k, A_x, A, b_x, b_y)\n",
    "        X_k_t = X_k\n",
    "        derphi=1\n",
    "        while f_xp >= f_x: #- alpha * stp * derphi:\n",
    "            stp *= beta\n",
    "            X_k_t = _step_noautograd(stp, X_k, A_x, A_y, b_x, b_y)    \n",
    "            f_xp = f(X_k_t, A_x, A_y, b_x, b_y)\n",
    "        \n",
    "            if stp < 1e-6:\n",
    "                break  \n",
    "\n",
    "        X_k = X_k_t\n",
    "        L = jnp.linalg.inv(C)@X_k.T@(A_x@X_k+E_0)\n",
    "        \n",
    "        report['lossh'].append(f_xp.item())\n",
    "        report['sln_path'].append(np.asarray(X_k))\n",
    "        report['L'].append(np.asarray(L))\n",
    "        report['step_sizes'].append(stp)\n",
    "        report['foc'].append(foc_pgd(X_k, L, C, A_x, b_x, b_y).item())\n",
    "        \n",
    "        if len(report['lossh']) > 2 and \\\n",
    "        np.abs(report['lossh'][-2] - report['lossh'][-1]) <= convergence_criterion:\n",
    "            print('converged')\n",
    "            break\n",
    "    report['x'] = X_k\n",
    "        \n",
    "    return report\n",
    "\n",
    "@jit\n",
    "def step(i, opt_state, A_x, A_y, b_x, b_y):\n",
    "    \"\"\"Perform a single gradient (using autograd) + projection step with adaptive momentum.\"\"\"\n",
    "    X_k = get_params(opt_state)\n",
    "    f_x, g = value_and_grad(f)(X_k, A_x, A_y, b_x, b_y)\n",
    "    return opt_update(i, g, opt_state), f_x\n",
    "\n",
    "def pgd_autograd(opt_params, A_x, A_y, b_x, b_y, C, convergence_criterion, maxiters=1000):\n",
    "    \"\"\"Perform iterations of PGD, with autograd \"\"\"\n",
    "    opt_state, opt_update, get_params = opt_params\n",
    "    X_k = get_params(opt_state)\n",
    "    E_0 = jnp.stack([b_x, b_y], axis=1)\n",
    "    L = jnp.linalg.inv(C)@X_k.T@(A_x@X_k+E_0)\n",
    "    \n",
    "    report = {'x':None, 'lossh':[f(X_k, A_x, A_y, b_x, b_y).item()], 'sln_path':[np.asarray(X_k)], \n",
    "            'foc':[foc_pgd(X_k, L, C, A_x, b_x, b_y).item()], 'step_sizes':[1], 'L':[L]}\n",
    "    \n",
    "    for k in tqdm(range(maxiters)):\n",
    "        opt_state, f_k = step(k, opt_state, A_x, A_y, b_x, b_y)\n",
    "        X_k = get_params(opt_state)\n",
    "\n",
    "        L = jnp.linalg.inv(C)@X_k.T@(A_x@X_k+E_0)\n",
    "\n",
    "        report['lossh'].append(f_k.item())\n",
    "        report['sln_path'].append(np.asarray(X_k))\n",
    "        report['L'].append(np.asarray(L))\n",
    "        report['foc'].append(foc_pgd(X_k, L, C, A_x, b_x, b_y).item())\n",
    "        \n",
    "        if len(report['lossh']) > 2 and \\\n",
    "        np.abs(report['lossh'][-2] - report['lossh'][-1]) <= convergence_criterion:\n",
    "            print('converged')\n",
    "            break\n",
    "            \n",
    "    report['x'] = X_k\n",
    "        \n",
    "    return report\n",
    "\n",
    "@jit\n",
    "def _step(i, opt_state, Z):\n",
    "    \"\"\"Perform a single descent + projection step with arbitrary descent direction.\"\"\"\n",
    "    return opt_update(i, Z, opt_state)\n",
    "\n",
    "def D_Z(X, A, d, e):\n",
    "    I = jnp.eye(A.shape[0])\n",
    "    Adinv = jnp.linalg.inv(A + d*I)\n",
    "    XtADinv = X.T@Adinv\n",
    "    Del = jnp.linalg.inv(XtADinv@X)@XtADinv@e\n",
    "    Z = Adinv@(-X@Del + e)\n",
    "    \n",
    "    return Del, Z\n",
    "\n",
    "@jit\n",
    "def sqp(A, L, E_0, X):\n",
    "    \"\"\"Perform an iteration of SQP.\"\"\" \n",
    "    I = jnp.eye(A.shape[0])\n",
    "    w = jnp.linalg.eigvals(L)\n",
    "    idx = w.argsort()[::-1]   \n",
    "    w = w[idx]\n",
    "    E = -E_0 - (A@X + X@L)\n",
    "    \n",
    "    Del_0, Z_0 = D_Z(X, A, w[0], E[:,0])\n",
    "    Del_1, Z_1 = D_Z(X, A, w[1], E[:,1])\n",
    "    \n",
    "    Z = jnp.stack([Z_0, Z_1], axis=1)\n",
    "    Del = jnp.stack([Del_0, Del_1], axis=1)\n",
    "    \n",
    "    return Z, Del    \n",
    "\n",
    "def newton(opt_params, A, A_L, L, C, X_k, b_x, b_y, convergence_criterion, \n",
    "           maxiters=100, alpha=1e-2, beta=0.9):\n",
    "    \"\"\"Perform iterations of PND + backtracking line search.\"\"\"    \n",
    "    opt_state, opt_update, get_params = opt_params\n",
    "    X_k = get_params(opt_state)\n",
    "    E_0 = np.stack([b_x, b_y], axis=1)\n",
    "    L = L_init(X_k, C, A, E_0)\n",
    "    #L_sym = (L + L.T)/2\n",
    "    #L = L_sym\n",
    "    \n",
    "    report = {'x':None, 'lossh':[f(X_k, A, A, b_x, b_y).item()], 'sln_path':[np.asarray(X_k)], \n",
    "            'foc':[foc_sqp(X_k, L, C, A, E_0).item()], 'step_sizes':[1], 'L':[L]}\n",
    "    \n",
    "    for k in tqdm(range(maxiters)):         \n",
    "        Z, Del = sqp(A, L, E_0, X_k)\n",
    "        \n",
    "        # backtracking line search\n",
    "        f_xp = 1e8\n",
    "        stp = 1\n",
    "        f_x, gr = value_and_grad(f)(X_k, A, A, b_x, b_y)\n",
    "        #derphi = jnp.trace(gr.T@Z)\n",
    "        derphi = 1\n",
    "        len_p = jnp.linalg.norm(Z)\n",
    "        X_k_t = X_k\n",
    "        \n",
    "        opt_state_t = opt_state\n",
    "        \n",
    "        while f_xp >= f_x: #- alpha * stp * derphi:\n",
    "            stp *= beta\n",
    "            opt_state_t = _step(stp, opt_state, -Z)\n",
    "            X_k_t = get_params(opt_state_t)\n",
    "            f_xp = f(X_k_t, A, A, b_x, b_y)\n",
    "        \n",
    "            if stp * len_p < 1e-8:\n",
    "                break    \n",
    "        L = L + stp*Del\n",
    "        foc = foc_sqp(X_k, L, C, A, E_0)\n",
    "        \n",
    "        opt_state = opt_state_t\n",
    "        X_k = get_params(opt_state_t)\n",
    "        \n",
    "        report['sln_path'].append(np.asarray(X_k))\n",
    "        report['step_sizes'].append(stp)\n",
    "        report['foc'].append(foc.item())\n",
    "        report['lossh'].append(f_xp.item())\n",
    "        report['L'].append(np.asarray(L))\n",
    "        \n",
    "        if len(report['lossh']) > 2 and np.abs(report['lossh'][-2] - report['lossh'][-1]) <= convergence_criterion:\n",
    "            print('converged')\n",
    "            break\n",
    "            \n",
    "    return report\n",
    "    \n",
    "def ssm():\n",
    "    \"\"\"\n",
    "    1. compute newton direction z = sqp(X, Z, v, Ax + E0) & subspace S\n",
    "    2. approximate locally optimal X, L on S; X = min F(\\hat{X}, B, V.T@E0)\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def map_vars(A, X_k, fixed_indices, centercons):\n",
    "    \"\"\"Preprocess variables \"\"\" \n",
    "    N = A.shape[0] \n",
    "    k = fixed_indices.shape[0]\n",
    "    fixed_idx = np.zeros((k,N))\n",
    "    for i in range(k):\n",
    "        fixed_idx[i,fixed_indices[i]] += 1\n",
    "    if k>0:\n",
    "        fixed_coordsx = X_k[fixed_indices,0]\n",
    "        fixed_coordsy = X_k[fixed_indices,1]\n",
    "        \n",
    "        constraints = np.concatenate([fixed_idx,np.expand_dims(1-fixed_idx.sum(0),0)])\n",
    "        fixed_coordsx = np.concatenate([fixed_coordsx,np.expand_dims(centercons[0],0)])\n",
    "        fixed_coordsy = np.concatenate([fixed_coordsy,np.expand_dims(centercons[1],0)])\n",
    "        P = null_space(constraints).T\n",
    "        #_,P = qr_null(constraints).T\n",
    "        \n",
    "        pinvcons = np.linalg.pinv(constraints)\n",
    "        \n",
    "        n0_x = (pinvcons@fixed_coordsx)\n",
    "        b_x = (P@(A@n0_x))\n",
    "        \n",
    "        n0_y = (pinvcons@fixed_coordsy)\n",
    "        b_y = (P@(A@n0_y))\n",
    "        A = (P@A@P.T)\n",
    "    else:\n",
    "        constraints = np.expand_dims(np.ones(n),0)    \n",
    "        P = null_space(constraints).T\n",
    "        #_,P = qr_null(constraints).T\n",
    "        \n",
    "        pinvcons = np.linalg.pinv(constraints)\n",
    "        n0_x = pinvcons@(np.expand_dims(centercons[0],0))\n",
    "        b_x = P@(A@n0_x)\n",
    "\n",
    "        n0_y = pinvcons@(np.expand_dims(centercons[1],0))\n",
    "        b_y = P@(A@n0_y)\n",
    "        \n",
    "        b_x = np.zeros_like(b_x)\n",
    "        b_y = np.zeros_like(b_x)\n",
    "        \n",
    "        A = P@A@P.T \n",
    "        \n",
    "    return A, P, b_x, b_y, n0_x, n0_y, fixed_idx\n",
    "    \n",
    "\n",
    "def cluster(rng, opt_params, X_k, A, mapped_vars, fixed_indices, maxiters=1000, convergence_criterion=1e-3,\n",
    "            c1=1, c2=1, c3=0, centroid=jnp.array([0,0]), centercons=None, v=None, D=None, eps=1e-8, method='pgd'):\n",
    "    \"\"\"Given an adjacency matrix A and initialization X_k, optimize X.\"\"\"\n",
    "    method = method.lower()\n",
    "    global opt_update\n",
    "    #opt_init, opt_update, get_params = opt_params    \n",
    "    \n",
    "    \n",
    "    assert method in ['pgd','pnd','ssm']\n",
    "    assert len(A.shape) == 2\n",
    "    assert A.shape[0] == X_k.shape[0]\n",
    "    \n",
    "    k = fixed_indices.shape[0]\n",
    "    fixed_coordsx = X_k[fixed_indices,0]\n",
    "    fixed_coordsy = X_k[fixed_indices,1]\n",
    "\n",
    "    N = A.shape[0]\n",
    "\n",
    "    if v is None:\n",
    "        v = jnp.ones(N)\n",
    "    if D is None:\n",
    "        D = jnp.diag(v)\n",
    "    if centercons is None:\n",
    "        centercons = jnp.zeros(2)\n",
    "    A_L = A\n",
    "    A, P, b_x, b_y, n0_x, n0_y, fixed_idx = mapped_vars\n",
    "\n",
    "    C = jnp.block([[c1, c3],[c3, c2]])\n",
    "\n",
    "    assert jnp.linalg.det(C) > 1e-5\n",
    "    E_0 = jnp.stack([b_x, b_y], axis=1)\n",
    "    \n",
    "    n0 = jnp.stack([n0_x,n0_y],axis=0)\n",
    "    X_k_n = jnp.array(np.linalg.pinv(P.T)@(X_k-n0.T))\n",
    "    X_k_n = project(X_k_n, C, E_0, centercons)\n",
    "    L = np.eye(2)\n",
    "\n",
    "    if method == \"pgd\":\n",
    "        opt_init, opt_update, get_params = opt_params\n",
    "        opt_state = opt_init(X_k_n)\n",
    "        A_x = A\n",
    "        A_y = A\n",
    "\n",
    "        #result = pgd_autograd((opt_state, opt_update, get_params), A_x, A_y, b_x, b_y, C, \n",
    "        #                      convergence_criterion=convergence_criterion, maxiters=maxiters) \n",
    "            \n",
    "        result = pgd(X_k_n, A_x, A_y, b_x, b_y, C, \n",
    "                        convergence_criterion=convergence_criterion, maxiters=maxiters, alpha=0.5, beta=0.9)  \n",
    "    elif method == \"pnd\":\n",
    "        opt_init, opt_update, get_params = opt_params\n",
    "        opt_state = opt_init(X_k_n)\n",
    "        result = newton((opt_state, opt_update, get_params), A, A_L, L, C, X_k_n, b_x, b_y, \n",
    "                        convergence_criterion=convergence_criterion, maxiters=maxiters, alpha=0.0, beta=0.9)        \n",
    "    else:\n",
    "        print(\"method not supported\")\n",
    "        assert False\n",
    "    X_k = result['sln_path'][np.argmin(result['lossh'])]\n",
    "    X_k = project(X_k, C, E_0, centercons)\n",
    "    X_k_n = np.zeros((N,2))\n",
    "    X_k_n[:,0] = np.array(P.T@X_k[:,0]) + n0_x.T\n",
    "    X_k_n[:,1] = np.array(P.T@X_k[:,1]) + n0_y.T\n",
    "        \n",
    "    result['x'] = X_k_n\n",
    "    \n",
    "    mask = (1-fixed_idx.sum(0)).astype(np.bool)\n",
    "    result['mask'] = mask\n",
    "    result['centroid'] = centercons\n",
    "    if fixed_idx.sum() == 0:\n",
    "        result['g'] = np.array(g(X_k_n, v, centercons))\n",
    "        result['h'] = np.array(h(X_k_n, np.diag(v), c1, c2, c3, centroid))      \n",
    "    else:\n",
    "        result['g'] = np.array(g(X_k_n[mask], v[mask], centercons))\n",
    "        result['h'] = np.array(h(X_k_n[mask], np.diag(v[mask]), c1, c2, c3, centroid))\n",
    "    result['P'] = (P)\n",
    "    result['e'] = np.vstack([b_x,b_y])\n",
    "    result['n'] = (n0_x, n0_y)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### USER PARAMETERS #####\n",
    "method = \"pnd\" # pnd or pgd\n",
    "\n",
    "\n",
    "seed = 0 # random seed\n",
    "eps = 1e-8 # global epsilon variable\n",
    "rng = random.PRNGKey(seed)\n",
    "key, subkey = jax.random.split(rng)\n",
    "\n",
    "v = np.ones(n)\n",
    "c1=v.sum()*10**2*1/12\n",
    "c2=v.sum()*10**2*1/12\n",
    "c3=0\n",
    "C = jnp.block([[c1, c3],[c3, c2]])\n",
    "\n",
    "X_k_r = (random.normal(subkey, (n,2))*np.sqrt(10))\n",
    "\n",
    "if os.path.isfile(graphdir+graphpostfix+'_evals.npy') and \\\n",
    "   os.path.isfile(graphdir+graphpostfix+'_evecs.npy'):\n",
    "    w = np.load(graphdir+graphpostfix+'_evals.npy')\n",
    "    v = np.load(graphdir+graphpostfix+'_evecs.npy')    \n",
    "else:\n",
    "    w,v = sp.sparse.linalg.eigsh(L, k=5, which='SM')\n",
    "    np.save(graphdir+graphpostfix+'_evals.npy',w)\n",
    "    np.save(graphdir+graphpostfix+'_evecs.npy',v)\n",
    "w,v = sp.sparse.linalg.eigsh(L, k=min(n,5), which='SM')\n",
    "X_k = v[:,1:3].real\n",
    "\n",
    "if DEBUG:\n",
    "    fixed_indices = np.array([0])\n",
    "else:\n",
    "    fixed_indices = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "\n",
    "X_k[fixed_indices] = X_k_r[fixed_indices]\n",
    "\n",
    "#X_k = X_k.astype(jnp.float16)\n",
    "#L = L.astype(jnp.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del w\n",
    "del v\n",
    "del X_k_r\n",
    "v = jnp.ones(n)\n",
    "A, P, b_x, b_y, n0_x, n0_y, fixed_idx = map_vars(L, X_k, fixed_indices, v.sum()*jnp.array([0,0]))\n",
    "mapped_vars = (A, P, b_x, b_y, n0_x, n0_y, fixed_idx)\n",
    "\n",
    "if method == \"pgd\":\n",
    "    pgd_lr = 5e-2\n",
    "    opt_init, opt_update, get_params = padam(pgd_lr,partial(lambda x, y, z: project(z, y, x), \n",
    "                                                    np.stack([b_x,b_y],axis=1), C), b1=0.9, b2=0.999, eps=1e-08)\n",
    "\n",
    "elif method == \"pnd\":\n",
    "    opt_init, opt_update, get_params = psgd(partial(lambda x, y, z: project(z, y, x), \n",
    "                                                    np.stack([b_x,b_y],axis=1), C))\n",
    "else:\n",
    "    print('method not supported')\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1acfa1fa41a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m result = cluster(rng, (opt_init, opt_update, get_params), \n\u001b[1;32m      2\u001b[0m                  \u001b[0mX_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapped_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentercons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  v=None, D=None, eps=1e-8, maxiters=1000, convergence_criterion=1e-8, method=method)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_k_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-c2934e84169e>\u001b[0m in \u001b[0;36mcluster\u001b[0;34m(rng, opt_params, X_k, A, mapped_vars, fixed_indices, maxiters, convergence_criterion, c1, c2, c3, centroid, centercons, v, D, eps, method)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mn0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn0_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn0_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mX_k_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_k\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mX_k_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_k_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentercons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(a, rcond, hermitian)\u001b[0m\n\u001b[1;32m   2001\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2002\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2003\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhermitian\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhermitian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2005\u001b[0m     \u001b[0;31m# discard small singular values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1662\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = cluster(rng, (opt_init, opt_update, get_params), \n",
    "                 X_k, L, mapped_vars, fixed_indices=fixed_indices,c1=c1, c2=c2, c3=c3, centercons=v.sum()*jnp.array([0,0]), \n",
    "                 v=None, D=None, eps=1e-8, maxiters=1000, convergence_criterion=1e-8, method=method)\n",
    "results = [result]\n",
    "X_k_n=result['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = utils.plot_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_id, voxel_bound = voxel_cluster(X_k, np.array([5, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils.plot_graph(X_k, graph, title='loss: {} h: {} g: {} foc: {}'.format(str(np.round(np.min(result['lossh']),2)), \n",
    "#                                                                            np.round(result['g'],2), np.round(result['g'],2), \n",
    "#                                                                           str(np.round(result['foc'][np.argmin(result['lossh'])],2))), fixed_indices=fixed_indices, c=voxel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "utils.plot_graph(X_k_n, graph, title='loss: {} h: {} g: {} foc: {}'.format(str(np.round(np.min(result['lossh']),2)), \n",
    "                                                                            np.round(result['h'],2), np.round(result['g'],2), \n",
    "                                                                           str(np.round(result['foc'][np.argmin(result['lossh'])],2))), fixed_indices=fixed_indices, c=voxel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
